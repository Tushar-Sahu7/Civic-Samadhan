{"description":"We are building the technical plan for the Civic Samadhan prototype (MERN + Python AI). This plan must generate code + infra + dummy data and implement prototype AI logic (keyword-based + random scoring) and map integration. 1) High-level goals - Deliver a working prototype that demonstrates full issue lifecycle: complaint submission → AI categorization → duplicate detection & batching → dept assignment by admin → staff assignment → status lifecycle (Acknowledged → Staff Assigned → In Progress → Resolved) → citizen feedback. - Stack: React (web PWA), Node.js/Express backend, Python microservice for AI logic (use Gemini API for production integration later), PostgreSQL primary datastore (PostGIS extension optional), Redis for cache/notifications, S3-compatible for media, Leaflet for maps. - Constraints: single-region deployment, DB in India, demo-scale (thousands of complaints), role-based auth (visitor, citizen, staff, department, admin). - Deliverables: - DB schema (Postgres) + sample SQL create scripts. - Dummy data generation scripts (users, staff, departments, complaints, issues). - Backend API contract (REST) and minimal implementation scaffolding. - AI microservice prototype (keyword-based categorization + random scoring). - Duplicate detection & batching worker (spatial + text + image-hash heuristics). - Frontend React pages: landing, login/signup, citizen dashboard, complaint form, map with Leaflet pins, department dashboard. - Simple deployment docs (Docker + Docker Compose or Kubernetes manifests). - README describing how to run locally. 2) Data model (Postgres) — create these tables and sample columns - users: - user_id (uuid PK), name, phone, email, role (visitor/citizen/staff/department/admin), created_at - departments: - dept_id (uuid PK), name, contact_email, phone, created_at - staff: - staff_id (uuid PK), user_id (fk), dept_id (fk), role (primary/support), shift_info - complaints: - complaint_id (uuid PK), title, description, media_url, report_time (timestamp), user_id (fk), lat, lon, category (nullable), raw_priority_score (jsonb), linked_issue_id (nullable fk) - issues: - issue_id (uuid PK), title, description, location_lat, location_lon, generation_time, category, progress_status (acknowledged / staff_assigned / in_progress / resolved), assigned_staff_id (nullable fk), staff_role, department_id (fk), priority_score (numeric 0..1), merged_count (int), metadata (jsonb) - feedbacks: - feedback_id, issue_id (fk), user_id (fk), rating (1..5), comments, proof_media_url, created_at - ai_insights: - insight_id, complaint_id, suggested_category, confidence, priority_components (jsonb), created_at - logs/audit: generic audit table for actions Provide SQL CREATE TABLE examples for each (include PostGIS geometry if desired: geometry(Point,4326)). Also define indexes for geospatial queries (GIST on geometry) and text search (GIN on description). 3) Dummy data generation - Provide a node/python script that inserts: - 200 fake citizens (names, phones, emails) - 20 staff accounts across 4 departments (Roads, Electricity, Water, Sanitation) - 4 departments seeded - 1000 complaints randomly distributed across Jharkhand-ish lat/lon bounding box (or arbitrary city coords for demo) - Random media_url placeholders - Complaints fields: id,title,description,report_time,user_id,lat,lon,category=null (so AI will assign). - Issue table initially empty; batching worker will create issues by grouping complaints. - Include example sample records in the prompt (3 complaints, 1 staff, 1 issue) to show shape. 4) AI Categorization + Priority scoring (prototype logic) - Implement prototype AI microservice (Python FastAPI) that: - Receives complaint record (title, description, media_url, lat, lon). - **Categorization**: keyword-based mapping (lower-case token match): - roads_keywords = ["pothole","road","crack","sinkhole"] - water_keywords = ["water","leak","sewage","overflow"] - electricity_keywords = ["light","lamp","electric","power","outage"] - sanitation_keywords = ["garbage","trash","bin","drainage","sewage"] - fallback: "other" - If multiple keywords match, pick highest count; if none, "other". - **Duplicate check**: simple heuristic - Spatial proximity: find existing complaints within radius R (configurable, default 50m) using PostGIS ST_DWithin (or haversine fallback). - Text similarity: compute simple normalized token overlap Jaccard or use sentence-transformer if available; for prototype use token overlap > 0.5. - Image dedup: (optional prototype) use perceptual hash stub — if same placeholder hash then duplicate. - If spatial + text similarity threshold exceeded => considered duplicate. - **Batching/Merging**: - When duplicate is found, attach complaint.linked_issue_id = existing_issue_id and increment issue.merged_count. - If not found, create new issue with aggregated title/description from first complaint. - **Priority Score**: compute numeric between 0 and 1 by weighted sum of: - severity_heuristic (keyword weights; e.g., “danger”, “collapse” → high) - reports_count_norm = min(1, sqrt(number_of_linked_complaints)/10) - location_sensitivity (if near POI like hospital/school => +0.2) - time_factor (older complaints → higher) - random_noise (small rand between 0 and 0.1 to break ties) - For prototype: calculate each component as 0..1 (keyword_hit->0.8 etc.) and final priority = weighted sum (e.g., 0.4*severity + 0.25*reports_count + 0.2*location_sensitivity + 0.1*time_factor + 0.05*rand). Store breakdown in ai_insights.priority_components. - Return category + priority_score + confidence. 5) Batching worker/service - A background worker (Node.js or Python) that: - Polls new complaints (unlinked). For each: - Call AI service → get category, priority. - Check duplicate within time window (48-72h) and radius R. - If match → link to issue; else create issue row with assigned department = category → status = acknowledged → priority_score saved. - Push notification to department head queue (Redis). - Expose admin endpoint to manually merge/unmerge issues. 6) Assignment workflow - Department head UI: list of new issues with suggested priority and candidate staff. - Admin/Department head **assigns** staff; **AI DOES NOT ASSIGN STAFF** (per your note). - When assigned, issue.progress_status = staff_assigned and staff receives notification. - Staff updates status to in_progress/resolved and uploads proof_media_url. On resolved, issue.progress_status=resolved and feedback request sent to original complainants and linked supporters. 7) APIs (sample) - POST /api/auth/login, /api/auth/signup (OTP/email) - POST /api/complaints → stores complaint, returns complaint_id - GET /api/complaints/:id - GET /api/complaints?user_id=... - GET /api/issues → list/filter by bbox/category/status - GET /api/issues/:id → includes linked complaints - POST /api/issues/:id/assign → body { assigned_staff_id } - POST /api/issues/:id/status → update status - GET /api/map/pins?bbox=... → return issues as pins (id, lat, lon, category, priority) - Admin endpoints: /api/admin/merge, /api/admin/unmerge, /api/admin/metrics 8) Frontend map integration (Leaflet) - Use Leaflet (open-source) with OpenStreetMap tiles or Mapbox free tier. - Implement a map component that calls /api/map/pins with bounding box of visible map and renders pins as categorized icons. - Clicking a pin opens a side panel with issue details (title, status, linked complaints count, upvote/join button). - For demo, use randomly generated coords and pin colors by priority (green->low, yellow->mid, red->high). - Include clustering for dense areas (Leaflet.markercluster). 9) Sample dummy data schema + example records (show 3 examples) - Provide 3 sample complaint JSONs and 2 sample issue JSONs in the prompt. 10) Deployment & infra (prototype) - Recommend Docker Compose for prototype: - services: postgres, redis, api (node), ai-service (python), frontend (react), worker - For staging/prod: Kubernetes with namespaces per environment, Helm charts. - Log/monitor: simple Prometheus + Grafana or use hosted service. 11) Security & constraints - JWT auth, role-based middleware, CORS, rate-limiting (Redis). - Data residency: Postgres hosted in India region. - PII: phone/email stored encrypted, consent recorded on signup. 12) Testing & validation - Unit tests for AI rules, duplicate detection logic, and API endpoints. - Load test guidelines (k6) to simulate peaks. 13) Variations to produce - Provide two plan variants: A) Monolith-first (single repo Node backend with AI prototype as separate Python service) — faster to ship. B) Microservices (separate services per domain: auth, complaints, AI, notifications, analytics) — better long-term scaling. 14) Outputs requested from coding agent - SQL create scripts + sample insert scripts (dummy data). - Python FastAPI AI microservice with endpoints: POST /classify, POST /batch_check - Node/Express backend skeleton with the listed REST APIs (controllers, models). - Dummy frontend React pages: complaint form, citizen dashboard map, issue detail modal, department head list. - Docker Compose + README to run locally. - A short migration plan to move from shared-schema to schema-per-tenant DB if needed. Please generate the technical plan, scaffold code, and dummy data scripts based on the above. Prioritize a working local prototype (Docker Compose) that demonstrates the full issue lifecycle end-to-end. as you will see most of the folders and frontend are already designed but not functional make plans to make it functional responsive}